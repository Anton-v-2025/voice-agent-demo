<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            font-family: 'Arial', sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            color: white;
        }
        .container {
            text-align: center;
            padding: 40px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
        }
        .status {
            font-size: 24px;
            margin-bottom: 20px;
            font-weight: bold;
        }
        .indicator {
            width: 80px;
            height: 80px;
            margin: 20px auto;
            border-radius: 50%;
            background: #4CAF50;
            animation: pulse 2s infinite;
        }
        .indicator.listening {
            background: #2196F3;
        }
        .indicator.speaking {
            background: #FF5722;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.1); opacity: 0.8; }
        }
        .info {
            margin-top: 20px;
            font-size: 14px;
            opacity: 0.8;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="status" id="status">Инициализация...</div>
        <div class="indicator" id="indicator"></div>
        <div class="info" id="info">Подключение к AI агенту</div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let audioQueue = [];
        let isPlaying = false;

        const statusEl = document.getElementById('status');
        const indicatorEl = document.getElementById('indicator');
        const infoEl = document.getElementById('info');

        function updateStatus(status, info = '') {
            statusEl.textContent = status;
            if (info) infoEl.textContent = info;
        }

        function setIndicator(state) {
            indicatorEl.className = 'indicator ' + state;
        }

        // Подключение к OpenAI Realtime API
        async function connectToOpenAI() {
            // Получаем API ключ из URL параметра
            const urlParams = new URLSearchParams(window.location.search);
            const apiKey = urlParams.get('key');
            
            if (!apiKey) {
                updateStatus('Ошибка', 'API ключ не найден в URL');
                return;
            }
            
            try {
                updateStatus('Подключение к AI...', 'Установка соединения');
                
                ws = new WebSocket('wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01', [
                    'realtime',
                    `openai-insecure-api-key.${apiKey}`,
                    'openai-beta.realtime-v1'
                ]);

                ws.addEventListener('open', () => {
                    console.log('Connected to OpenAI Realtime API');
                    updateStatus('Агент готов', 'Слушаю...');
                    setIndicator('listening');
                    
                    // Отправляем конфигурацию сессии
                    ws.send(JSON.stringify({
                        type: 'session.update',
                        session: {
                            modalities: ['text', 'audio'],
                            instructions: 'Ты HR-агент компании ESSG. Твоя задача - проводить собеседования с кандидатами. Будь дружелюбным, профессиональным и задавай релевантные вопросы о навыках и опыте кандидата.',
                            voice: 'alloy',
                            input_audio_format: 'pcm16',
                            output_audio_format: 'pcm16',
                            input_audio_transcription: {
                                model: 'whisper-1'
                            },
                            turn_detection: {
                                type: 'server_vad',
                                threshold: 0.5,
                                prefix_padding_ms: 300,
                                silence_duration_ms: 500
                            }
                        }
                    }));
                });

                ws.addEventListener('message', async (event) => {
                    const data = JSON.parse(event.data);
                    console.log('Received:', data.type);

                    if (data.type === 'response.audio.delta') {
                        // Получаем аудио от OpenAI
                        const audioData = atob(data.delta);
                        const audioArray = new Uint8Array(audioData.length);
                        for (let i = 0; i < audioData.length; i++) {
                            audioArray[i] = audioData.charCodeAt(i);
                        }
                        audioQueue.push(audioArray);
                        playAudioQueue();
                    }

                    if (data.type === 'response.audio.done') {
                        updateStatus('Агент готов', 'Слушаю...');
                        setIndicator('listening');
                    }

                    if (data.type === 'response.audio_transcript.delta') {
                        updateStatus('Агент говорит', data.delta);
                        setIndicator('speaking');
                    }

                    if (data.type === 'conversation.item.input_audio_transcription.completed') {
                        infoEl.textContent = 'Вы: ' + data.transcript;
                    }
                });

                ws.addEventListener('error', (error) => {
                    console.error('WebSocket error:', error);
                    updateStatus('Ошибка', 'Проблема с подключением');
                    setIndicator('');
                });

                ws.addEventListener('close', () => {
                    console.log('WebSocket closed');
                    updateStatus('Отключено', 'Переподключение...');
                    setTimeout(connectToOpenAI, 3000);
                });

            } catch (error) {
                console.error('Error connecting:', error);
                updateStatus('Ошибка', error.message);
            }
        }

        // Воспроизведение аудио
        async function playAudioQueue() {
            if (isPlaying || audioQueue.length === 0) return;
            
            isPlaying = true;
            
            if (!audioContext) {
                audioContext = new AudioContext({ sampleRate: 24000 });
            }

            while (audioQueue.length > 0) {
                const audioData = audioQueue.shift();
                
                // Конвертируем PCM16 в AudioBuffer
                const audioBuffer = audioContext.createBuffer(1, audioData.length / 2, 24000);
                const channelData = audioBuffer.getChannelData(0);
                
                for (let i = 0; i < audioData.length; i += 2) {
                    const sample = (audioData[i] | (audioData[i + 1] << 8));
                    channelData[i / 2] = sample < 0x8000 ? sample / 0x8000 : (sample - 0x10000) / 0x8000;
                }

                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                
                await new Promise((resolve) => {
                    source.onended = resolve;
                    source.start();
                });
            }
            
            isPlaying = false;
        }

        // Захват аудио из встречи
        async function startAudioCapture() {
            try {
                updateStatus('Получение аудио...', 'Доступ к микрофону');
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 24000
                    } 
                });
                
                updateStatus('Обработка аудио...', 'Настройка потока');
                
                // Используем AudioContext для обработки
                const captureContext = new AudioContext({ sampleRate: 24000 });
                const source = captureContext.createMediaStreamSource(stream);
                const processor = captureContext.createScriptProcessor(4096, 1, 1);
                
                source.connect(processor);
                processor.connect(captureContext.destination);
                
                updateStatus('Готов к работе', 'Аудио подключено');

                processor.onaudioprocess = (e) => {
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        
                        // Конвертируем Float32 в PCM16
                        const pcm16 = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            const s = Math.max(-1, Math.min(1, inputData[i]));
                            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        }
                        
                        // Отправляем в OpenAI
                        const base64Audio = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));
                        
                        ws.send(JSON.stringify({
                            type: 'input_audio_buffer.append',
                            audio: base64Audio
                        }));
                    }
                };

            } catch (error) {
                console.error('Error capturing audio:', error);
                updateStatus('Ошибка аудио', error.message);
            }
        }

        // Запуск при загрузке
        window.addEventListener('load', async () => {
            try {
                await connectToOpenAI();
                // Небольшая задержка перед захватом аудио
                setTimeout(startAudioCapture, 2000);
            } catch (error) {
                console.error('Initialization error:', error);
                updateStatus('Ошибка', error.message);
            }
        });
    </script>
</body>
</html>
